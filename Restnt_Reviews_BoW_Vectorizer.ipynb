{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Restnt_Reviews_BoW_Vectorizer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sumitdua10/CNN_Text_Classification_Restaurent_Reviews/blob/master/Restnt_Reviews_BoW_Vectorizer.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "fkb84erCaXJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6197f94b-249c-473b-bfe1-2a573416210d"
      },
      "cell_type": "code",
      "source": [
        "# Natural Language Processing to classify the restaurent reviews whether they are favorable or not. Uses a supervised Learning algorithm\n",
        "# Main File. It uses a Bags of words approach.\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Importing the dataset\n",
        "\n",
        "FILENAME = \"https://raw.githubusercontent.com/sumitdua10/CNN_Text_Classification_Restaurent_Reviews/master/Restaurent_reviews.tsv\"\n",
        "#TestFile = FILENAME = \"C:\\\\Users\\\\IBM_ADMIN\\\\Desktop\\\\Personal\\\\Trainings\\\\Machine Learning\\\\Data\\\\Udemy\\\\Machine Learning A-Z Template Folder\\\\Part 7 - Natural Language Processing\\\\Section 36 - Natural Language Processing\\\\test.tsv\"\n",
        "dataset = pd.read_csv(FILENAME, delimiter = '\\t', error_bad_lines=False)#, quoting = 3, skipfooter=500)#, header = None, skiprows=1)\n",
        "Num_Words = dataset.shape[0]\n",
        "print(dataset.head())\n",
        "print(dataset.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              Review  Liked\n",
            "0                           Wow... Loved this place.      1\n",
            "1                                 Crust is not good.      0\n",
            "2          Not tasty and the texture was just nasty.      0\n",
            "3  Stopped by during the late May bank holiday of...      1\n",
            "4  The selection on the menu was great and so wer...      1\n",
            "(1000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E-wOrHydcuDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a4a2268c-febc-4d79-ef87-da57cddebf3c"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 2. Download the stop words\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []\n",
        "s = stopwords.words('english')\n",
        "print(len(s))\n",
        "\n",
        "#print(type(s))\n",
        "s.remove('not')\n",
        "print(len(s))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "179\n",
            "178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CFPAbMepgYTa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ly5u464UgYzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2acfc87f-c686-453b-c624-8121ddb23515"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#corpus.append(review)\n",
        "#print(corpus)\n",
        "# 3. Remove th  e puncuation symbols or any other symbols that are not characters [^A-Za-z] and put the text in list Corpus\n",
        "# 3. Optionaly you can also stem them using porterstemmer. This part of code might be commented below.\n",
        "print(\"Original text: \", dataset['Review'][0])\n",
        "corpus = []\n",
        "for i in range(0, Num_Words):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
        "    review = review.lower()\n",
        "    #review = review.split()\n",
        "    #ps = PorterStemmer()\n",
        "    #review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    #review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "\n",
        "\n",
        "#print(len(corpus))\n",
        "print(\"First text after removing puncatation: \", corpus[0])\n",
        "#print(corpus.size)\n",
        "#print(corpus.shape)\n",
        "#print(corpus[0])\n",
        "#corpus.remove((corpus[0]))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:  Wow... Loved this place.\n",
            "First text after removing puncatation:  wow    loved this place \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xgr3OvmMhcjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "94ba740c-e3b8-4abe-a352-f9371c4cf0b8"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Create the Bag of Words model using CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "cv = CountVectorizer(ngram_range = (1,3)).fit(corpus) # creates features columns with ngrams of size 1, 2 and 3\n",
        "\n",
        "fnames = cv.get_feature_names()\n",
        "print(\"No. of features from simple vectorizer with (1,3) ngrams = \",len(fnames))\n",
        "\n",
        "tv = TfidfVectorizer(ngram_range = (1,3), max_df=0.15).fit(corpus) # min_df=1, max_df = 0.5\n",
        "\n",
        "fnames_tv = tv.get_feature_names()\n",
        "print(\"No. of features from tfidf vectorizer with (1,3) ngrams= \",len(fnames_tv))\n",
        "\n",
        "y = dataset.iloc[:, 1].values # y is the output 1 indicates favorable and 0 indicates not good."
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of features from simple vectorizer with (1,3) ngrams =  16465\n",
            "No. of features from tfidf vectorizer with (1,3) ngrams=  16460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LpOOgWXmuN2f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "def train_evaluate(v,y):\n",
        "  \n",
        "  X_cv = v.transform(corpus).toarray()\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_cv, y, test_size = 0.20, random_state=123)\n",
        "\n",
        "  # Fitting Naive Bayes to the Training set\n",
        "  import sklearn.naive_bayes as nb\n",
        "  import sklearn.linear_model as lm\n",
        "\n",
        "  #classifier =  lm.SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
        "  #classifier = nb.BernoulliNB()\n",
        "  classifier =LogisticRegression()#random_state = 1)\n",
        "  #classifier = GaussianNB()\n",
        "  classifier.fit(X_train, y_train)\n",
        "\n",
        "  # Predicting the Test set results\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  #y_dec = classifier.decision_function(X_test)\n",
        "  y_prob = classifier.predict_proba(X_test)\n",
        "  print(\"Accuracy Score is \", accuracy_score(y_test, y_pred))\n",
        "  print(\"F1 Score is \", f1_score(y_test, y_pred))\n",
        "  print(\"ROC AUC Score is \", roc_auc_score(y_test, y_pred))\n",
        "  print(\"Top 5 features are :\")\n",
        "  #print(list(classifier.get_params()[:5]))\n",
        "  index = np.argpartition(classifier.coef_,-5, axis=None)[-5:]\n",
        "    #print(v.get_feature_names()[index])\n",
        "  print(list(zip(pd.Series(v.get_feature_names())[index], classifier.coef_[0,index])))\n",
        "  \n",
        "  return classifier#print(classifier.coef_.shape)\n",
        "    #print(\"ROC AUC Score is \", roc_auc_score(y_test, y_prob))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NLatvzjfsua3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "40a4874c-2870-4c7c-b95d-6ed9f285ae07"
      },
      "cell_type": "code",
      "source": [
        "#5. Split the training set and train on Naive_Byes algorithm\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "\n",
        "print(\"Accuracy score from simple vectorizer is :\")\n",
        "classifier_v= train_evaluate(cv,y)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score from simple vectorizer is :\n",
            "Accuracy Score is  0.785\n",
            "F1 Score is  0.7981220657276996\n",
            "ROC AUC Score is  0.7837092731829574\n",
            "Top 5 features are :\n",
            "[('awesome', 0.9742135751679531), ('delicious', 1.3975597149973336), ('amazing', 1.260670799655687), ('great', 1.9597132885718827), ('good', 1.488608600774885)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pirSzcL7-mu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1676aad9-111c-4abc-8da9-c3acbd50a006"
      },
      "cell_type": "code",
      "source": [
        "print(\"Accuracy score from tfidf vectorizer is :\")\n",
        "classifier_t = train_evaluate(tv,y)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score from tfidf vectorizer is :\n",
            "Accuracy Score is  0.785\n",
            "F1 Score is  0.7860696517412935\n",
            "ROC AUC Score is  0.7867167919799498\n",
            "Top 5 features are :\n",
            "[('nice', 0.9169707670279265), ('amazing', 1.1696054005138004), ('delicious', 1.3535502853078656), ('good', 1.6475629558732934), ('great', 2.300096582491733)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "se-L4QfLHDXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ac8bc8ef-e4c2-45ce-d081-9df8e6e9ebc7"
      },
      "cell_type": "code",
      "source": [
        "inputtext = \"food was not that good\"\n",
        "review = re.sub('[^a-zA-Z]', ' ', inputtext)\n",
        "review = review.lower()\n",
        "\n",
        "print(review)\n",
        "\n",
        "x = list()\n",
        "x = [review]\n",
        "print(x)\n",
        "#list.append(review)\n",
        "#corpus.append(review)\n",
        "#print(len(corpus))\n",
        "#print(corpus[-1])\n",
        "#cv = CountVectorizer()#max_features = 1500)\n",
        "#X_test_run = cv.fit_transform(corpus).toarray()\n",
        "\n",
        "x_new = cv.transform(x).toarray()\n",
        "print(x_new.shape)\n",
        "#print(X_test_run.shape)\n",
        "y = classifier_v.predict(x_new)\n",
        "print(\"Classifier Response is \",y[-1])\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "food was not that good\n",
            "['food was not that good']\n",
            "(1, 16465)\n",
            "Classifier Response is  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b2gDamj8LxmB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Restnt_Reviews_BoW_Vectorizer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sumitdua10/CNN_Text_Classification_Restaurent_Reviews/blob/master/Restnt_Reviews_BoW_Vectorizer.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "fkb84erCaXJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "986ea58f-6811-488e-b6aa-96a75171a23b"
      },
      "cell_type": "code",
      "source": [
        "# Natural Language Processing to classify the restaurent reviews whether they are favorable or not. Uses a supervised Learning algorithm\n",
        "# Main File. It uses a Bags of words approach.\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pda\n",
        "\n",
        "# 1. Importing the dataset\n",
        "\n",
        "FILENAME = \"https://raw.githubusercontent.com/sumitdua10/CNN_Text_Classification_Restaurent_Reviews/master/Restaurent_reviews.tsv\"\n",
        "#TestFile = FILENAME = \"C:\\\\Users\\\\IBM_ADMIN\\\\Desktop\\\\Personal\\\\Trainings\\\\Machine Learning\\\\Data\\\\Udemy\\\\Machine Learning A-Z Template Folder\\\\Part 7 - Natural Language Processing\\\\Section 36 - Natural Language Processing\\\\test.tsv\"\n",
        "dataset = pd.read_csv(FILENAME, delimiter = '\\t', error_bad_lines=False)#, quoting = 3, skipfooter=500)#, header = None, skiprows=1)\n",
        "Num_Words = dataset.shape[0]\n",
        "print(dataset.head())\n",
        "print(dataset.shape)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              Review  Liked\n",
            "0                           Wow... Loved this place.      1\n",
            "1                                 Crust is not good.      0\n",
            "2          Not tasty and the texture was just nasty.      0\n",
            "3  Stopped by during the late May bank holiday of...      1\n",
            "4  The selection on the menu was great and so wer...      1\n",
            "(1000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E-wOrHydcuDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d19eb72f-e2bb-4e35-dc23-b0a89b11eb88"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 2. Download the stop words\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []\n",
        "s = stopwords.words('english')\n",
        "print(len(s))\n",
        "\n",
        "#print(type(s))\n",
        "s.remove('not')\n",
        "print(len(s))\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "179\n",
            "178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CFPAbMepgYTa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ly5u464UgYzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61a572f8-0015-4bb1-f19e-3b3d1b890b29"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#corpus.append(review)\n",
        "#print(corpus)\n",
        "# 3. Remove th  e puncuation symbols or any other symbols that are not characters [^A-Za-z] and put the text in list Corpus\n",
        "# 3. Optionaly you can also stem them using porterstemmer. This part of code might be commented below.\n",
        "print(\"Original text: \", dataset['Review'][0])\n",
        "corpus = []\n",
        "for i in range(0, Num_Words):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
        "    review = review.lower()\n",
        "    #review = review.split()\n",
        "    #ps = PorterStemmer()\n",
        "    #review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    #review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "\n",
        "\n",
        "#print(len(corpus))\n",
        "print(\"First text after removing puncatation: \", corpus[0])\n",
        "#print(corpus.size)\n",
        "#print(corpus.shape)\n",
        "#print(corpus[0])\n",
        "#corpus.remove((corpus[0]))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text  Wow... Loved this place.\n",
            "First text is after removing puncatation wow    loved this place \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xgr3OvmMhcjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6013bcb8-3622-449e-98fc-68446d91249f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Create the Bag of Words model using CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(ngram_range = (1,3)).fit(corpus) # creates features columns with ngrams of size 1, 2 and 3\n",
        "fnames = cv.get_feature_names()\n",
        "print(len(fnames))\n",
        "X = cv.transform(corpus).toarray()\n",
        "print(X.shape)\n",
        "print(type(X))\n",
        "y = dataset.iloc[:, 1].values # y is the output 1 indicates favorable and 0 indicates not good.\n",
        "#print(y[0:5])\n",
        "#print(corpus[0:5])\n",
        "\n",
        "#5. Split the training set and train on Naive_Byes algorithm\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
        "\n",
        "# Fitting Naive Bayes to the Training set\n",
        "import sklearn.naive_bayes as nb\n",
        "import sklearn.linear_model as lm\n",
        "\n",
        "#classifier =  lm.SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
        "#classifier = nb.BernoulliNB()\n",
        "classifier = nb.MultinomialNB()#random_state = 1)\n",
        "#classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "#y_dec = classifier.decision_function(X_test)\n",
        "y_prob = classifier.predict_proba(X_test)\n",
        "#df = pd.DataFrame(X_test)\n",
        "#df[1:2] = y_prob\n",
        "#print(df.head())\n",
        "#df.to_csv(TestFile)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16465\n",
            "(1000, 16465)\n",
            "<class 'numpy.ndarray'>\n",
            "[1 0 0 1 1]\n",
            "['wow    loved this place ', 'crust is not good ', 'not tasty and the texture was just nasty ', 'stopped by during the late may bank holiday off rick steve recommendation and loved it ', 'the selection on the menu was great and so were the prices ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bXuA1GQxiRC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a8c89f3e-e8af-4dc1-fbe0-99745e693aea"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#print(y_prob.shape)\n",
        "#print(y_pred.shape)\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "print(\"Accuracy Score is \", accuracy_score(y_test, y_pred))\n",
        "print(\"F1 Score is \", f1_score(y_test, y_pred))\n",
        "print(\"ROC AUC Score is \", roc_auc_score(y_test, y_pred))\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[71 26]\n",
            " [12 91]]\n",
            "Accuracy Score is  0.81\n",
            "F1 Score is  0.8272727272727274\n",
            "ROC AUC Score is  0.807726954258833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YuRpn319iyZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#inputtext = input(\"Enter the question\")\n",
        "inputtext = \"food was not good\"\n",
        "review = re.sub('[^a-zA-Z]', ' ', inputtext)\n",
        "review = review.lower()\n",
        "#review = review.split()\n",
        "print(review)\n",
        "#review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "#review = ' '.join(review)\n",
        "\n",
        "print(review)\n",
        "\n",
        "\n",
        "x = list()\n",
        "x = [review]\n",
        "print(x)\n",
        "#list.append(review)\n",
        "#corpus.append(review)\n",
        "#print(len(corpus))\n",
        "#print(corpus[-1])\n",
        "#cv = CountVectorizer()#max_features = 1500)\n",
        "#X_test_run = cv.fit_transform(corpus).toarray()\n",
        "\n",
        "x_new = cv.transform(x).toarray()\n",
        "print(x_new.shape)\n",
        "#print(X_test_run.shape)\n",
        "y = classifier.predict(x_new)\n",
        "print(\"Classifier Response is \",y[-1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}